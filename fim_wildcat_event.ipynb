{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wildcat Creek 2018 Labor Day Flood Inundation Mapping\n",
    "\n",
    "This notebook uses the Wildcat Creek (near Manhattan, KS) Labor Day flood event in 2018 to demonstarte how to map the flood event using FLDPLN tiled library."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules\n",
    "\n",
    "Import necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from dask import visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import FLDPLN Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool/script folder\n",
    "fldplnToolFolder = r'E:\\CUAHSI_SI\\training\\source' # tool development folder, has the latest version\n",
    "\n",
    "# Add the tool/script folder to sys.path to access fldpln modules\n",
    "sys.path.append(fldplnToolFolder) \n",
    "# fldpln module\n",
    "from fldpln import *\n",
    "from fldpln_library import *\n",
    "from fldpln_gauge import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Input Tiled Library and Output Folders\n",
    "\n",
    "Here we setup the folder under which tiled libraries (organized as folders) are located. We also setup the output folder (i.e., outputFolder) under which a map folder and a 'scratch' folder are created. The map folder, which is specified later, comtains all inundation depth maps. The scratch folder stores temporary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiled library folder\n",
    "libFolder =  r'E:\\CUAHSI_SI\\training\\examples\\wildcat_10m_3dep\\tiled_snz_library'\n",
    "\n",
    "# libraries to be mapped\n",
    "allLibNames = ['lib_py']\n",
    "\n",
    "# Set output folder\n",
    "outputFolder = r'E:\\CUAHSI_SI\\training\\examples\\wildcat_10m_3dep\\maps'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Gauge Stage and Calculate Gauge Depth of Flow (DOF)\n",
    "\n",
    "Here we obtain and prepare flood event stages from stream gauges. The stage at a gauge typically refers to the gauge's datum, which is not necessary of the stream bed elevation which is based on a certain vertical datum. In order to use gauge stage in a FLDPLN library, we need to make sure that gauge stage elevation (gauage + stage) and FSP's filled elevation are based on the same vertical datum. The depth of flow (DOF) at the FSP can then be calculated as the difference. The Wildcat Creek DEM and FLDPLN library are based on the NAVD88 vertical datum. So gauge stage elevations need to be based on the vertical datum too to calculate the DOFs at those gauges. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gauge Stage from AHPS and USGS\n",
    "\n",
    "Both USGS and NWS AHPS maintain stream gauages which record past flood stages. There are three AHPS and USGS gauges ([WKCK1](https://water.weather.gov/ahps2/hydrograph.php?wfo=top&gage=wkck1), [MWCK1](https://water.weather.gov/ahps2/hydrograph.php?wfo=top&gage=MWCK1), [MSTK1](https://water.weather.gov/ahps2/hydrograph.php?wfo=top&gage=MSTK1)) on the Wildcat Creek that record the 2018 Labor Day flood event. Here we use the maximum Labor Day flood event stages at those gauges to map the maximum inundation extent and depth of the event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event Stage from AHPS Historic Crests\n",
    "\n",
    "The flood stage for the 2018 Labor Day flood event in 2018 are availble as AHPS histroic crests at those gauges [WKCK1](https://water.noaa.gov/gauges/WKCK1), [MWCK1](https://water.weather.gov/ahps2/hydrograph.php?wfo=top&gage=MWCK1) and [MSTK1](https://water.weather.gov/ahps2/hydrograph.php?wfo=top&gage=MSTK1). Excel file wildcat_gauges_albers_meters.xlsx has several sheets which store both gauge information (for example, gauge datum) and the event statges with different gauge combinations. The key fields needed for those gauges are: stationid, x, y, and stage_elevation\n",
    "\n",
    "Note that most USGS and AHPS gauge stages are measured in feet and **Make sure that gauge coordinates are in the same coordinate system of the library and gauge stages are also in the same vertical unit of the library.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        stationid           x             y  stage_elevation\n",
      "0  06879805,WKCK1 -60735.0580  1.799635e+06       343.911936\n",
      "1  06879810,MWCK1 -54988.6141  1.796210e+06       325.907400\n",
      "2  06879815,MSTK1 -52277.2352  1.795783e+06       317.851536\n"
     ]
    }
   ],
   "source": [
    "# # Two downstream gauges \n",
    "# gaugeStageFileName = 'wildcat_gauges.xlsx' # KS LiDAR DEM in UTM with vertical unit in feet\n",
    "gaugeStageFileName = 'wildcat_gauges_albers_meters.xlsx' # 3DEP DEM in Albers with vertical unit in meters\n",
    "sheetName = 'ThreeGauges' # all 3 gauges\n",
    "# sheetName = 'TwoDsGauges' # 2 downstream gauges\n",
    "# sheetName = 'MSTK1' # the last downstream gauge used in HEC-RAS model\n",
    "\n",
    "# read gauge file\n",
    "gaugeStages = pd.read_excel(gaugeStageFileName, sheet_name=sheetName) \n",
    "# print(gaugeStages)\n",
    "\n",
    "# Need to calculate gauge stage elevation if necessary!\n",
    "\n",
    "# keep only necessary fields from gauges\n",
    "keptFields = ['stationid','x','y','stage_elevation']\n",
    "gaugeWithStageElevations = gaugeStages[keptFields]\n",
    "print(gaugeWithStageElevations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event Stage from USGS NWIS\n",
    "\n",
    "We can also get event maximum stage directly from USGS NWIS to cehck the historic crests from AHPS. Note that the stages are in feet and we need to convert stages to stage elevation before using it in flood inundation mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fjgomez1\\AppData\\Local\\anaconda3\\envs\\fldpln\\Lib\\site-packages\\urllib3\\connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'waterservices.usgs.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\fjgomez1\\AppData\\Local\\anaconda3\\envs\\fldpln\\Lib\\site-packages\\urllib3\\connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'waterservices.usgs.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\fjgomez1\\AppData\\Local\\anaconda3\\envs\\fldpln\\Lib\\site-packages\\urllib3\\connectionpool.py:1103: InsecureRequestWarning: Unverified HTTPS request is being made to host 'nwis.waterservices.usgs.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stationid  stage_ft                     stage_time\n",
      "0    06879805      6.87  2018-09-02T00:00:00.000-05:00\n",
      "1    06879805      6.87  2018-09-02T00:15:00.000-05:00\n",
      "2    06879805      6.87  2018-09-02T00:30:00.000-05:00\n",
      "3    06879805      6.87  2018-09-02T00:45:00.000-05:00\n",
      "4    06879805      6.87  2018-09-02T01:00:00.000-05:00\n",
      "..        ...       ...                            ...\n",
      "812  06879815      5.73  2018-09-04T22:45:00.000-05:00\n",
      "813  06879815      5.73  2018-09-04T23:00:00.000-05:00\n",
      "814  06879815      5.72  2018-09-04T23:15:00.000-05:00\n",
      "815  06879815      5.72  2018-09-04T23:30:00.000-05:00\n",
      "816  06879815      5.71  2018-09-04T23:45:00.000-05:00\n",
      "\n",
      "[817 rows x 3 columns]\n",
      "  stationid  stage_ft                     stage_time\n",
      "0  06879805     25.97  2018-09-03T04:45:00.000-05:00\n",
      "1  06879810     28.29  2018-09-03T07:00:00.000-05:00\n",
      "2  06879815     25.18  2018-09-03T08:30:00.000-05:00\n"
     ]
    }
   ],
   "source": [
    "# Wildcat Creek 3 USGS gauges (in the order from upstream to downstream)\n",
    "usgsIds = ['06879805','06879810','06879815'] \n",
    "ahpsIds = ['WKCK1','MWCK1','MSTK1']\n",
    "\n",
    "# A period between two dates: Wildcat Creek Sep.3 2018 flood event\n",
    "instStages = GetUsgsGaugeStageFromWebService(usgsIds,startDate='2018-09-02',endDate='2018-09-04')\n",
    "print(instStages)\n",
    "\n",
    "# find the max stage within the time period\n",
    "maxStages = instStages.groupby(['stationid'],as_index=False).agg({'stage_ft':'max'})\n",
    "# find the most recent time with the max stage\n",
    "tdf = pd.merge(instStages, maxStages, how='inner', on=['stationid','stage_ft'])\n",
    "gaugeStagesFromNwis = tdf.groupby(['stationid'], as_index=False).agg({'stationid':'first','stage_ft':'first','stage_time':'max'})\n",
    "print(gaugeStagesFromNwis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Gauge Stage from the National Water Model and HAND\n",
    "\n",
    "HAND FIM uses NWM's discharge and turn it into stage. Here we use HAND reach stage to run FLDPLN for the event. Concepually, we turn reach stage into a synthetic gauge located at the either the mid-point or the outlet of the reach. Selecting the HAND reaches and sythteric gauge location is done by graduate student David Weiss manually for the Wildcat Creek example. Those sytheteic gauges can be treated as USGS/AHPS guages. The key fields needed are: stationid, x, y, and stage_elevation.  Note that we assume the HAND reach stage elevation is the same as the FLDPLN library DEM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stationid             x             y  FilledElev_FLDPLN   HydroID  \\\n",
      "0         1.0 -61538.205794  1.799968e+06        1123.727413  22160126   \n",
      "1         2.0 -60868.205794  1.799988e+06        1111.158236  22160123   \n",
      "2         3.0 -60798.205794  1.799258e+06        1107.293577  22160124   \n",
      "3         4.0 -60088.205794  1.799138e+06        1101.593758  22160125   \n",
      "4         5.0 -58898.205794  1.798198e+06        1093.053342  22160110   \n",
      "5         6.0 -58148.205794  1.797518e+06        1079.412746  22160111   \n",
      "6         7.0 -57358.205794  1.797018e+06        1074.712158  22160104   \n",
      "7         8.0 -56828.205794  1.796868e+06        1067.207817  22160101   \n",
      "8         9.0 -56308.205794  1.796368e+06        1066.029766  22160100   \n",
      "9        10.0 -56068.205794  1.796758e+06        1059.294473  22160093   \n",
      "10       11.0 -55898.205794  1.796548e+06        1053.092636  22160094   \n",
      "11       12.0 -55208.205794  1.796178e+06        1048.627037  22160095   \n",
      "12       13.0 -54528.205794  1.795848e+06        1042.787547  22160096   \n",
      "13       14.0 -54558.205794  1.795528e+06        1041.878928  22160082   \n",
      "14       15.0 -53638.205794  1.795408e+06        1036.353524  22160083   \n",
      "15       16.0 -53478.205794  1.795718e+06        1033.168602  22160084   \n",
      "16       17.0 -53348.205794  1.795968e+06        1029.360613  22160078   \n",
      "17       18.0 -53028.205794  1.796078e+06        1027.566905  22160079   \n",
      "18       19.0 -52348.205794  1.795858e+06        1022.721538  22160075   \n",
      "19       20.0 -52078.205794  1.795998e+06        1018.380893  22160076   \n",
      "20       21.0 -51348.205794  1.795608e+06        1013.890264  22160070   \n",
      "21       22.0 -51378.205794  1.794348e+06        1006.454408  22160071   \n",
      "22       23.0 -50738.205794  1.793998e+06        1001.720979  22160072   \n",
      "23        NaN -50658.205794  1.793928e+06        1001.553974  22160062   \n",
      "\n",
      "    feature_id  stage_inund  discharge_cms  stage_elevation  \n",
      "0     18841108       4.1179     215.751422       346.630015  \n",
      "1     18841120       4.1216     274.720255       342.802630  \n",
      "2     18841120       5.3338     235.369957       342.836882  \n",
      "3     18841120       5.2601     244.564758       341.025877  \n",
      "4     18841142       5.5476     306.889837       338.710258  \n",
      "5     18841142       5.3029     299.452012       334.307905  \n",
      "6     18841144       6.0051     353.529937       333.577365  \n",
      "7     18841148       5.1870     353.350074       330.471942  \n",
      "8     18841154       6.3175     355.074764       331.243373  \n",
      "9     18841166       5.7956     325.507125       328.668555  \n",
      "10    18841166       5.6169     305.584274       326.599535  \n",
      "11    18841166       6.5337     310.869884       326.155221  \n",
      "12    18841166       6.0492     331.896509       323.890844  \n",
      "13    18841176       6.6915     327.053620       324.256197  \n",
      "14    18841176       5.8341     320.345645       321.714654  \n",
      "15    18841176       6.5430     306.141363       321.452790  \n",
      "16    18841168       7.1132     286.800219       320.862315  \n",
      "17    18841168       6.6169     304.710938       319.819293  \n",
      "18    18841170       5.2438     282.559700       316.969325  \n",
      "19    18841170       5.9614     307.419491       316.363896  \n",
      "20    18841666       5.7577     286.681143       314.791452  \n",
      "21    18841666       5.6703     294.226959       312.437603  \n",
      "22    18841666       6.1420     278.520333       311.466555  \n",
      "23    18841210       1.1748      10.765245       306.448451  \n",
      "    stationid             x             y  stage_elevation\n",
      "0         1.0 -61538.205794  1.799968e+06       346.630015\n",
      "1         2.0 -60868.205794  1.799988e+06       342.802630\n",
      "2         3.0 -60798.205794  1.799258e+06       342.836882\n",
      "3         4.0 -60088.205794  1.799138e+06       341.025877\n",
      "4         5.0 -58898.205794  1.798198e+06       338.710258\n",
      "5         6.0 -58148.205794  1.797518e+06       334.307905\n",
      "6         7.0 -57358.205794  1.797018e+06       333.577365\n",
      "7         8.0 -56828.205794  1.796868e+06       330.471942\n",
      "8         9.0 -56308.205794  1.796368e+06       331.243373\n",
      "9        10.0 -56068.205794  1.796758e+06       328.668555\n",
      "10       11.0 -55898.205794  1.796548e+06       326.599535\n",
      "11       12.0 -55208.205794  1.796178e+06       326.155221\n",
      "12       13.0 -54528.205794  1.795848e+06       323.890844\n",
      "13       14.0 -54558.205794  1.795528e+06       324.256197\n",
      "14       15.0 -53638.205794  1.795408e+06       321.714654\n",
      "15       16.0 -53478.205794  1.795718e+06       321.452790\n",
      "16       17.0 -53348.205794  1.795968e+06       320.862315\n",
      "17       18.0 -53028.205794  1.796078e+06       319.819293\n",
      "18       19.0 -52348.205794  1.795858e+06       316.969325\n",
      "19       20.0 -52078.205794  1.795998e+06       316.363896\n",
      "20       21.0 -51348.205794  1.795608e+06       314.791452\n",
      "21       22.0 -51378.205794  1.794348e+06       312.437603\n",
      "22       23.0 -50738.205794  1.793998e+06       311.466555\n",
      "23        NaN -50658.205794  1.793928e+06       306.448451\n"
     ]
    }
   ],
   "source": [
    "# Synthetic FSP gauges from NWC reach stage\n",
    "# gaugeStageFileName = 'wildcat_gauges.xlsx'\n",
    "# sheetName = 'ReachStageAsDof' \n",
    "gaugeStageFileName = 'wildcat_gauges_albers_meters.xlsx'\n",
    "# sheetName = 'ReachMedianStage' # HAND reach median stage as DOF\n",
    "sheetName = 'ReachOutletStage' # HAND reach outlet stage as DOF\n",
    "\n",
    "# read gauge file\n",
    "gaugeStages = pd.read_excel(gaugeStageFileName, sheet_name=sheetName) # 3 gauges\n",
    "print(gaugeStages)\n",
    "\n",
    "# Need to calculate gauge stage elevation if necessary!\n",
    "\n",
    "# keep only necessary fields from gauges\n",
    "keptFields = ['stationid','x','y','stage_elevation']\n",
    "gaugeWithStageElevations = gaugeStages[keptFields]\n",
    "print(gaugeWithStageElevations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snap Gauges to FSPs and Calculate Gauge DOF\n",
    "\n",
    "Here we snap gauges (with their stage elevation) to FLDPLN flood source pixels (FSPs), which are the stream pixels. Each snapped gauge FSP has a stream bed elevaltion, which is used to claculate the depth of flow/flood (DOF) at those FSPs. \n",
    "\n",
    "This process also identifies the FLDPLN libraries that the gauges belong to. Note that the same gauges can be snapped to more than one library as FLDPLN libraries may overlap and the overalpping FSPs may have different coordinates! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snap gauges to FSPs ...\n",
      "Number of gauges: 24\n",
      "    index  stationid             x             y  stage_elevation  \\\n",
      "0       0        1.0 -61538.205794  1.799968e+06       346.630015   \n",
      "1       1        2.0 -60868.205794  1.799988e+06       342.802630   \n",
      "2       2        3.0 -60798.205794  1.799258e+06       342.836882   \n",
      "3       3        4.0 -60088.205794  1.799138e+06       341.025877   \n",
      "4       4        5.0 -58898.205794  1.798198e+06       338.710258   \n",
      "5       5        6.0 -58148.205794  1.797518e+06       334.307905   \n",
      "6       6        7.0 -57358.205794  1.797018e+06       333.577365   \n",
      "7       7        8.0 -56828.205794  1.796868e+06       330.471942   \n",
      "8       8        9.0 -56308.205794  1.796368e+06       331.243373   \n",
      "9       9       10.0 -56068.205794  1.796758e+06       328.668555   \n",
      "10     10       11.0 -55898.205794  1.796548e+06       326.599535   \n",
      "11     11       12.0 -55208.205794  1.796178e+06       326.155221   \n",
      "12     12       13.0 -54528.205794  1.795848e+06       323.890844   \n",
      "13     13       14.0 -54558.205794  1.795528e+06       324.256197   \n",
      "14     14       15.0 -53638.205794  1.795408e+06       321.714654   \n",
      "15     15       16.0 -53478.205794  1.795718e+06       321.452790   \n",
      "16     16       17.0 -53348.205794  1.795968e+06       320.862315   \n",
      "17     17       18.0 -53028.205794  1.796078e+06       319.819293   \n",
      "18     18       19.0 -52348.205794  1.795858e+06       316.969325   \n",
      "19     19       20.0 -52078.205794  1.795998e+06       316.363896   \n",
      "20     20       21.0 -51348.205794  1.795608e+06       314.791452   \n",
      "21     21       22.0 -51378.205794  1.794348e+06       312.437603   \n",
      "22     22       23.0 -50738.205794  1.793998e+06       311.466555   \n",
      "23     23        NaN -50658.205794  1.793928e+06       306.448451   \n",
      "\n",
      "    d2NearestFsp          FspX          FspY  StrOrd        DsDist  SegId  \\\n",
      "0   1.001172e-08 -61538.205794  1.799968e+06     1.0  31140.318882    1.0   \n",
      "1   1.001172e-08 -60868.205794  1.799988e+06     1.0  29592.501423    2.0   \n",
      "2   1.001172e-08 -60798.205794  1.799258e+06     1.0  28197.110371    3.0   \n",
      "3   1.001172e-08 -60088.205794  1.799138e+06     1.0  27207.282810    4.0   \n",
      "4   1.001172e-08 -58898.205794  1.798198e+06     1.0  25413.191181    4.0   \n",
      "5   1.001172e-08 -58148.205794  1.797518e+06     1.0  24105.373721    4.0   \n",
      "6   1.001172e-08 -57358.205794  1.797018e+06     1.0  22873.119754    5.0   \n",
      "7   1.001172e-08 -56828.205794  1.796868e+06     1.0  22078.145007    6.0   \n",
      "8   1.001172e-08 -56308.205794  1.796368e+06     1.0  20597.901141    7.0   \n",
      "9   1.001172e-08 -56068.205794  1.796758e+06     1.0  19283.220767    8.0   \n",
      "10  1.001172e-08 -55898.205794  1.796548e+06     1.0  18011.261172    9.0   \n",
      "11  1.001172e-08 -55208.205794  1.796178e+06     1.0  16752.438662    9.0   \n",
      "12  1.001172e-08 -54528.205794  1.795848e+06     1.0  15562.611101    9.0   \n",
      "13  1.001172e-08 -54558.205794  1.795528e+06     1.0  14517.636354   10.0   \n",
      "14  1.001172e-08 -53638.205794  1.795408e+06     1.0  13464.082964   10.0   \n",
      "15  1.001172e-08 -53478.205794  1.795718e+06     1.0  12268.397539   12.0   \n",
      "16  1.001172e-08 -53348.205794  1.795968e+06     1.0  11353.422792   12.0   \n",
      "17  1.001172e-08 -53028.205794  1.796078e+06     1.0  10351.879503   12.0   \n",
      "18  1.001172e-08 -52348.205794  1.795858e+06     1.0   9325.189027   12.0   \n",
      "19  1.001172e-08 -52078.205794  1.795998e+06     1.0   8718.204179   12.0   \n",
      "20  1.001172e-08 -51348.205794  1.795608e+06     1.0   7100.386720   13.0   \n",
      "21  1.001172e-08 -51378.205794  1.794348e+06     1.0   5513.990617   13.0   \n",
      "22  1.001172e-08 -50738.205794  1.793998e+06     1.0   3980.315293   14.0   \n",
      "23  1.001172e-08 -50658.205794  1.793928e+06     1.0   3865.462479   14.0   \n",
      "\n",
      "    FilledElev lib_name  \n",
      "0   342.512115   lib_py  \n",
      "1   338.681030   lib_py  \n",
      "2   337.503082   lib_py  \n",
      "3   335.765778   lib_py  \n",
      "4   333.162659   lib_py  \n",
      "5   329.005005   lib_py  \n",
      "6   327.572266   lib_py  \n",
      "7   325.284943   lib_py  \n",
      "8   324.925873   lib_py  \n",
      "9   322.872955   lib_py  \n",
      "10  320.982635   lib_py  \n",
      "11  319.621521   lib_py  \n",
      "12  317.841644   lib_py  \n",
      "13  317.564697   lib_py  \n",
      "14  315.880554   lib_py  \n",
      "15  314.909790   lib_py  \n",
      "16  313.749115   lib_py  \n",
      "17  313.202393   lib_py  \n",
      "18  311.725525   lib_py  \n",
      "19  310.402496   lib_py  \n",
      "20  309.033752   lib_py  \n",
      "21  306.767303   lib_py  \n",
      "22  305.324554   lib_py  \n",
      "23  305.273651   lib_py  \n",
      "Number of snapped gauge FSPs: 24\n",
      "Libraries gauges snapped to: ['lib_py']\n",
      "   lib_name          FspX          FspY  StrOrd        DsDist  SegId  \\\n",
      "0    lib_py -61538.205794  1.799968e+06     1.0  31140.318882    1.0   \n",
      "1    lib_py -60868.205794  1.799988e+06     1.0  29592.501423    2.0   \n",
      "2    lib_py -60798.205794  1.799258e+06     1.0  28197.110371    3.0   \n",
      "3    lib_py -60088.205794  1.799138e+06     1.0  27207.282810    4.0   \n",
      "4    lib_py -58898.205794  1.798198e+06     1.0  25413.191181    4.0   \n",
      "5    lib_py -58148.205794  1.797518e+06     1.0  24105.373721    4.0   \n",
      "6    lib_py -57358.205794  1.797018e+06     1.0  22873.119754    5.0   \n",
      "7    lib_py -56828.205794  1.796868e+06     1.0  22078.145007    6.0   \n",
      "8    lib_py -56308.205794  1.796368e+06     1.0  20597.901141    7.0   \n",
      "9    lib_py -56068.205794  1.796758e+06     1.0  19283.220767    8.0   \n",
      "10   lib_py -55898.205794  1.796548e+06     1.0  18011.261172    9.0   \n",
      "11   lib_py -55208.205794  1.796178e+06     1.0  16752.438662    9.0   \n",
      "12   lib_py -54528.205794  1.795848e+06     1.0  15562.611101    9.0   \n",
      "13   lib_py -54558.205794  1.795528e+06     1.0  14517.636354   10.0   \n",
      "14   lib_py -53638.205794  1.795408e+06     1.0  13464.082964   10.0   \n",
      "15   lib_py -53478.205794  1.795718e+06     1.0  12268.397539   12.0   \n",
      "16   lib_py -53348.205794  1.795968e+06     1.0  11353.422792   12.0   \n",
      "17   lib_py -53028.205794  1.796078e+06     1.0  10351.879503   12.0   \n",
      "18   lib_py -52348.205794  1.795858e+06     1.0   9325.189027   12.0   \n",
      "19   lib_py -52078.205794  1.795998e+06     1.0   8718.204179   12.0   \n",
      "20   lib_py -51348.205794  1.795608e+06     1.0   7100.386720   13.0   \n",
      "21   lib_py -51378.205794  1.794348e+06     1.0   5513.990617   13.0   \n",
      "22   lib_py -50738.205794  1.793998e+06     1.0   3980.315293   14.0   \n",
      "23   lib_py -50658.205794  1.793928e+06     1.0   3865.462479   14.0   \n",
      "\n",
      "    FilledElev     Dof  \n",
      "0   342.512115  4.1179  \n",
      "1   338.681030  4.1216  \n",
      "2   337.503082  5.3338  \n",
      "3   335.765778  5.2601  \n",
      "4   333.162659  5.5476  \n",
      "5   329.005005  5.3029  \n",
      "6   327.572266  6.0051  \n",
      "7   325.284943  5.1870  \n",
      "8   324.925873  6.3175  \n",
      "9   322.872955  5.7956  \n",
      "10  320.982635  5.6169  \n",
      "11  319.621521  6.5337  \n",
      "12  317.841644  6.0492  \n",
      "13  317.564697  6.6915  \n",
      "14  315.880554  5.8341  \n",
      "15  314.909790  6.5430  \n",
      "16  313.749115  7.1132  \n",
      "17  313.202393  6.6169  \n",
      "18  311.725525  5.2438  \n",
      "19  310.402496  5.9614  \n",
      "20  309.033752  5.7577  \n",
      "21  306.767303  5.6703  \n",
      "22  305.324554  6.1420  \n",
      "23  305.273651  1.1748  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\CUAHSI_SI\\training\\source\\fldpln.py:93: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  nearestP2Df = pd.concat([nearestP2Df,t],ignore_index=False)\n"
     ]
    }
   ],
   "source": [
    "# snap gauges to FSPs on-the-fly\n",
    "print('Snap gauges to FSPs ...')\n",
    "print(f'Number of gauges: {len(gaugeWithStageElevations.index)}')\n",
    "\n",
    "# FLDPLN libraries to whose FSPs gauges are sanpped. All the libraries by default but can be a subset\n",
    "libs2Map = ['lib_py']\n",
    "\n",
    "# snap the gauges to FSPs. \n",
    "# Fields 'StrOrd','DsDist','SegId','FilledElev'are used for interpolating other FSP DOF\n",
    "# Note that 'lib_name','FspX', 'FspY' together uniquely identify a FSP (as there are overlapping FSPs between libraries)!\n",
    "gaugeFspDf = SnapGauges2Fsps(libFolder,libs2Map,gaugeWithStageElevations,snapDist=350,gaugeXField='x',gaugeYField='y',fspColumns=['FspX','FspY','StrOrd','DsDist','SegId','FilledElev']) \n",
    "print(gaugeFspDf)\n",
    "\n",
    "# calculate gauge FSP's DOF\n",
    "gaugeFspDf['Dof'] = gaugeFspDf['stage_elevation'] - gaugeFspDf['FilledElev']\n",
    "\n",
    "# keep only necessary columns for gauge FSPs\n",
    "gaugeFspDf = gaugeFspDf[['lib_name','FspX','FspY','StrOrd','DsDist','SegId','FilledElev','Dof']] # Note that 'lib_name','FspX', 'FspY' together uniquely identify a FSP!!!\n",
    "\n",
    "# show info\n",
    "print(f'Number of snapped gauge FSPs: {len(gaugeFspDf)}')\n",
    "# Find libs where the gauges are snapped to, and they are the actual libs to map\n",
    "libs2Map = gaugeFspDf['lib_name'].drop_duplicates().tolist()\n",
    "print(f'Libraries gauges snapped to: {libs2Map}')\n",
    "print(gaugeFspDf)\n",
    "\n",
    "#\n",
    "# save snapped gauges to CSV file for checking\n",
    "# gaugeFspDf.to_csv(os.path.join(outputFolder, 'SnappedGauges.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate FSP's DOF\n",
    "\n",
    "Here we interpolate the DOF for all the FSPs between the gauge-FSPs using their DOF calculated from previous step. The interpolation uses stream orders and starts from low stream order (i.e., main streams) to high stream order (i.e., tributatried). Either horizontal or vertical (by defaut) interpolation can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     LibName FspId       Dof\n",
      "0     lib_py     1  4.073070\n",
      "1     lib_py     2  4.076093\n",
      "2     lib_py     3  4.078231\n",
      "3     lib_py     4  4.081254\n",
      "4     lib_py     5  4.084277\n",
      "...      ...   ...       ...\n",
      "2329  lib_py  2330  3.263017\n",
      "2330  lib_py  2331  2.651393\n",
      "2331  lib_py  2332  2.039768\n",
      "2332  lib_py  2333  1.607284\n",
      "2333  lib_py  2334  1.174800\n",
      "\n",
      "[2334 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\CUAHSI_SI\\training\\source\\fldpln.py:523: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  fspDof = pd.concat([fspDof,fspOrd],ignore_index=True)\n",
      "C:\\Users\\fjgomez1\\AppData\\Local\\Temp\\ipykernel_28708\\3740564350.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  fspDof = pd.concat([fspDof,fspIdDof[['LibName','FspId','Dof']]], ignore_index=True)\n",
      "C:\\Users\\fjgomez1\\AppData\\Local\\Temp\\ipykernel_28708\\3740564350.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  fsps = pd.concat([fsps,fspDf], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Find libs with snapped gauges. They are the actual libs to map\n",
    "libs2Map = gaugeFspDf['lib_name'].drop_duplicates().tolist()\n",
    "\n",
    "# prepare the DF for storing interpolated FSP DOF\n",
    "fspDof = pd.DataFrame(columns=['LibName','FspId','Dof'])\n",
    "\n",
    "# prepare DFs for saving interpolated FSPs and their segment IDs\n",
    "fspCols = fspInfoColumnNames + ['Dof']\n",
    "segIdCols = ['SegId','LibName']\n",
    "fsps = pd.DataFrame(columns=fspCols)\n",
    "segIds =pd.DataFrame(columns=segIdCols)\n",
    "\n",
    "# map each library\n",
    "for libName in libs2Map:\n",
    "    # interpolate DOF for the gauges\n",
    "    # print('Interpolate FSP DOF using gauge DOF ...')\n",
    "    # fspIdDof = InterpolateFspDofFromGauge(libFolder,libName,gaugeFspDf) # 'V' by default\n",
    "    fspIdDof = InterpolateFspDofFromGauge(libFolder,libName,gaugeFspDf,weightingType='H') # horizontal interpolation\n",
    "    fspIdDof['LibName'] = libName\n",
    "    # fspDof = fspDof.append(fspIdDof[['LibName','FspId','Dof']], ignore_index=True)\n",
    "    fspDof = pd.concat([fspDof,fspIdDof[['LibName','FspId','Dof']]], ignore_index=True)\n",
    "\n",
    "    # Keep interpolated FSP DOF for saving later\n",
    "    fspFile = os.path.join(libFolder, libName, fspInfoFileName)\n",
    "    fspDf = pd.read_csv(fspFile) \n",
    "    fspDf = pd.merge(fspDf,fspDof,how='inner',on=['FspId'])\n",
    "    # fsps = fsps.append(fspDf, ignore_index=True)\n",
    "    fsps = pd.concat([fsps,fspDf], ignore_index=True)\n",
    "    \n",
    "    # Keep FSP segment IDs for saving later\n",
    "    t =  pd.DataFrame(fspDf['SegId'].drop_duplicates().sort_values())\n",
    "    t['LibName'] = libName\n",
    "    # segIds = segIds.append(t, ignore_index=True)\n",
    "    segIds = pd.concat([segIds,t], ignore_index=True)\n",
    "\n",
    "# show interpolated FSPs with Dof\n",
    "print(fspDof)\n",
    "\n",
    "#\n",
    "# save interpolated FSP DOF and their segments for checking. This block of code should be commented out if no-checking needed\n",
    "#\n",
    "# Save DOF and segment IDs to CSV files\n",
    "FspDofFile = os.path.join(outputFolder, 'Interpolated_FSP_DOF.csv')\n",
    "SegIdFile = os.path.join(outputFolder, 'Interpolated_SegIds.csv')\n",
    "fsps.to_csv(FspDofFile, index=False)\n",
    "segIds.to_csv(SegIdFile, index=False)\n",
    "\n",
    "# # turn interpolated sgements into a shapefile\n",
    "# for libName in libs2Map:\n",
    "#     segShp = os.path.join(libFolder, libName, 'stream_orders.shp')\n",
    "#     segs = gpd.read_file(segShp)\n",
    "#     segs['LibName'] = libName\n",
    "#     # print(segs)\n",
    "#     # join by two fields: SegId and LibName\n",
    "#     segDf = pd.merge(segs,segIds,how='inner',on=['SegId','LibName'])\n",
    "#     # print(segDf)\n",
    "#     # write segments as a shapefile\n",
    "#     segDf.to_file(os.path.join(outputFolder, 'Interpolated_Segements.shp'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Flood Inundation Depth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Mapping Parameters\n",
    "\n",
    "Setup the map folder (i.e., outMapFolderName) which is under the output folder and comtains all inundation depth maps. Additional settings include whether to mosaic tiles as single COG file and whether use a Dask local cluster to speed up the mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of workers: 6\n"
     ]
    }
   ],
   "source": [
    "# set up map folder\n",
    "outMapFolderName = 'labor_day_2018_AHPS_reach_outlet'\n",
    "\n",
    "# Create folders for storing temp and output map files\n",
    "outMapFolder,scratchFolder = CreateFolders(outputFolder,'scratch',outMapFolderName)\n",
    "\n",
    "# whether mosaci tiles as a single COG\n",
    "mosaicTiles = True #True #False\n",
    "\n",
    "# Using LocalCluster by default\n",
    "useLocalCluster = False # This doesn't work on my office desktop though it works fine on KBS server\n",
    "numOfWorkers = round(0.8*os.cpu_count())\n",
    "numOfWorkers = 6\n",
    "print(f'Number of workers: {numOfWorkers}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Inundation Depth\n",
    "\n",
    "The process of generating inundation depth map happens here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lib_py']\n"
     ]
    }
   ],
   "source": [
    "print(libs2Map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MapFloodDepthWithTiles_v1(libFolder,libName,fileFormat,outMapFolder,fspDof='MinDtf',aoiExtent=None):\n",
    "# fileFormat--'snappy' or 'mat'. 'snappy' format needs to install the 'fastparquet' python package\n",
    "# fspDof--Cab be 'MinDtf', 'NumOfFsps', 'Depression', a float number, and a DF of FSPs with DOF. \n",
    "#         When fspDof is a DF, it must have 3 columns ['FspX','FspY','Dof'] storing FSP's coordinates and DOF\n",
    "# aoiExtent--rectangle area interested, further limits the tiles decided by the FSPs' DOF. Can be None or a list of [minX,maxX,minY,maxY], default is None.\n",
    "# keepTileMaps--false or true, default is false\n",
    "# \n",
    "    # create the folder for generating tile maps\n",
    "    os.makedirs(outMapFolder,exist_ok=True)\n",
    "    # Read lib meta data file\n",
    "    metaDataFile = os.path.join(libFolder, libName, metaDataFileName)\n",
    "    with open(metaDataFile,'r') as jf:\n",
    "        md = json.load(jf)\n",
    "    cellSize = md['CellSize']\n",
    "    srText = md['SpatialReference']\n",
    "    libSr = rasterio.crs.CRS.from_wkt(srText)\n",
    "\n",
    "    # decide the tiles to map\n",
    "    tileIds,fppExtents = Tiles2Map_v1(libFolder,libName,fspDof,aoiExtent=None)  #FUNCTION 1 - Tiles2Map\n",
    "    print('Tiles need to be mapped:',tileIds)\n",
    "\n",
    "    # map the selected tile\n",
    "    if tileIds is None:\n",
    "        tileTifs = None\n",
    "    else:\n",
    "        tileTifs = []\n",
    "        for tid,fppExtent in zip(tileIds,fppExtents):    #FUNCTION 2 - MapOneTile\n",
    "            tif=MapOneTile_v1(libFolder,libName,tid,fppExtent,cellSize,libSr,fileFormat,outMapFolder,fspDof,aoiExtent)\n",
    "            if not(tif is None):\n",
    "                tileTifs.append(tif)\n",
    "        if not tileTifs: # empty list\n",
    "            tileTifs = None\n",
    "    \n",
    "    return tileTifs\n",
    "\n",
    "######################################################################################################################\n",
    "def Tiles2Map_v1(libFolder,libName,fspDof='MinDtf',aoiExtent=None):\n",
    "# Find the tiles need to be mapped for the library\n",
    "    # Read in the fsp-tile index and tile index files for selecting tiles for mapping\n",
    "    # read in fsp-tile index file to select the tiles for mapping\n",
    "    fspIdxFile = os.path.join(libFolder, libName, fspTileIndexFileName)\n",
    "    fspIdxDf = pd.read_csv(fspIdxFile)\n",
    "    # print(fspIdxDf)\n",
    "\n",
    "    # tile index file stores tile and FPP extents for the tile\n",
    "    tileIdxFile = os.path.join(libFolder, libName, tileIndexFileName)\n",
    "    tileIdxDf = pd.read_csv(tileIdxFile)\n",
    "    # print(tileIdxDf)\n",
    "    \n",
    "    # Select the tiles for mapping based on the FSPs and fsp-tile index\n",
    "    # for a dataframe of FSPs\n",
    "    elif isinstance(fspDof, pd.DataFrame):\n",
    "        # find which tiles need to be mapped\n",
    "        fspTiles = pd.merge(fspIdxDf, fspDof, how='inner', on=['FspId'])\n",
    "        # print(fspTiles)\n",
    "        # select those where DOF > minDtf\n",
    "        fspTiles = fspTiles[fspTiles['Dof']>fspTiles['MinDtf']]\n",
    "        # print(fspTiles)\n",
    "        # find the tiles need to be mapped\n",
    "        # fspTiles = fspTiles['TileId'].unique()\n",
    "        fspTiles = fspTiles['TileId'].drop_duplicates().sort_values().tolist()\n",
    "    else:\n",
    "        print(f'Unsupported fspDof type {fspDof}!')\n",
    "        return\n",
    "\n",
    "    # further limit the tiles to those that intersect with the AOI extent\n",
    "    if aoiExtent is None:\n",
    "        tiles = fspTiles\n",
    "    \n",
    "    # tiles selected\n",
    "    if len(tiles) == 0:\n",
    "        # print('No tile needs to be mapped!')\n",
    "        return None,None\n",
    "    else:\n",
    "        # get each tile's fppExtent\n",
    "        fppExtents=[]\n",
    "        for tid in tiles:\n",
    "            fppExtent = tileIdxDf[tileIdxDf['TileId']==tid].reset_index().loc[0,['FppMinX','FppMaxX','FppMinY','FppMaxY']].values.tolist()\n",
    "            fppExtents.append(fppExtent)\n",
    "        return tiles,fppExtents\n",
    "\n",
    "######################################################################################################################\n",
    "def MapOneTile_v1(libFolder,libName,tid,fppExtent,cellSize,libSr,fileFormat,outMapFolder,fspDof='MinDtf',aoiExtent=None):\n",
    "# Map one tile as a GeoTif file   \n",
    "    if fileFormat == 'snappy':\n",
    "        # tileName = os.path.join(libFolder, libName, tileFileMainName+'_'+str(tid)+'.gzip') # for gzip\n",
    "        tileName = os.path.join(libFolder, libName, tileFileMainName+'_'+str(tid)+'.snz') # for snappy\n",
    "        tdf = pd.read_parquet(tileName) # the original column datatypes are kept when read into a DF!\n",
    "\n",
    "    # Turn FSP-FPP relations to a 2D array\n",
    "    dtfArray, noData, mapMinX, mapMaxY = TileFspFppRelations2Array_v1(tdf, fppExtent, cellSize, fspDof, aoiExtent)\n",
    "    \n",
    "    # map the tile\n",
    "    if not (dtfArray is None): # needs to be mapped\n",
    "        # Create and save map as a GeoTif file\n",
    "        # print('Saving map as a TIF raster ...')\n",
    "        \n",
    "        # output file name\n",
    "        rasterName = os.path.join(outMapFolder,libName+'_tile_'+str(tid)+'.tif')\n",
    "        \n",
    "        # create GeoTIFF profile\n",
    "        # create an Affine transformation from upper left corner coordinates and pixel sizes\n",
    "        transform = rasterio.transform.from_origin(mapMinX, mapMaxY, cellSize, cellSize)\n",
    "        profile = dict(\n",
    "            driver=\"GTiff\",\n",
    "            height = dtfArray.shape[0], \n",
    "            width = dtfArray.shape[1],\n",
    "            count=1,\n",
    "            dtype=str(dtfArray.dtype),\n",
    "            crs=libSr,\n",
    "            transform=transform,\n",
    "            nodata=noData\n",
    "        )\n",
    "        \n",
    "        # write to COG file\n",
    "        with MemoryFile() as memfile:\n",
    "            # write the array to a memory file\n",
    "            with memfile.open(**profile) as mem:\n",
    "                # Populate the input file with numpy array\n",
    "                mem.write(dtfArray,1)\n",
    "            # open the memory file reading\n",
    "            with memfile.open(mode='r') as mem:\n",
    "                dst_profile = cog_profiles.get(\"deflate\")\n",
    "                cog_translate(\n",
    "                    mem,\n",
    "                    rasterName,\n",
    "                    dst_profile,\n",
    "                    in_memory=True,\n",
    "                    quiet=True,\n",
    "                )\n",
    "        return rasterName\n",
    "    \n",
    "        # # code to save tile as regular GeoTIFF file\n",
    "        # with rasterio.open(rasterName, 'w', **profile) as tifRaster:\n",
    "        #     tifRaster.write(dtfArray, 1)\n",
    "        # return rasterName\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "######################################################################################################################\n",
    "def TileFspFppRelations2Array_v1(fspFppRels, fppExtent, cellSize, fspDof='MinDtf', aoiExtent=None, noData=-9999):\n",
    "# The minimum bounding extent of the FPPs in the relations is always used when create the map for the tile!\n",
    "#\n",
    "# FspFppRels-- a dataframe of FSP-FPP relations which have the columns of [\"FspId\", \"FppCol\", \"FppRow\", \"Dtf\", \"FilledDepth\"] from a tile\n",
    "# fppExtent--a list of [minX, maxX, minY, maxY], FPP's external extent of the tile and is also used to locate FPP's columns and rows in map coordinate\n",
    "# fspDof--Cab be 'MinDtf', 'NumOfFsps', 'Depression', a float number, and a DF of FSP depth of flow, i.e., FSP stage. \n",
    "#         When fspDof is a table, it must have 3 columns ['FspX','FspY','Dof'] storing the coordinates and \"Depth of Flow\" for the FSPs\n",
    "# aoiExtent--None or a rectabgle extent of [minX, maxX, minY, maxY] that INTERSECTs with the fppExtent\n",
    "\n",
    "# Returns: dtfArray, noData, mapMinX, mapMinY\n",
    "\n",
    "    tdf = fspFppRels\n",
    "    # print('Number of FSP-FPP relations:', len(tdf))\n",
    "    if len(tdf)==0:\n",
    "        # no FPP needs to be mapping\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Calculate pixel values at each FPP based on the types of fspDof: 'MinDtf', 'NumOfFsps', 'Depression', a constant DOF, and a list of DOF\n",
    "    # Pixel value at each FPP is saved in the 'Dtf' column.\n",
    "    # Map the tile with a FSP DOF df\n",
    "    if isinstance(fspDof, pd.DataFrame):\n",
    "        # print('Map with a list of FSPs with DOFs ...')\n",
    "\n",
    "        # Only keep those relations whose DTF is less than or equal to the max interpolated DOF. \n",
    "        # This significantly saves memory and time when merge the relations with the DOFs!\n",
    "        maxDof = fspDof['Dof'].max()\n",
    "        tdf = tdf[tdf['Dtf'] < maxDof] # tdf.drop(tdf[tdf['Dtf']<=0].index, inplace=True) # saves memory than tdf = tdf[tdf['Dtf'] > 0]?\n",
    "        # print('Number of relations to be mapped: ',len(tdf))\n",
    "        \n",
    "        # set FSP DOF column data types to speed merge\n",
    "        fspDof = fspDof.astype(dtype={\"FspId\":np.int32,\"Dof\":np.float32},copy=False)\n",
    "\n",
    "        # create index to speed up merge\n",
    "        # tdf.astype(np.float32,copy=False).set_index(keys=['FspX','FspY'],inplace=True)\n",
    "        # fspDof.astype(np.float32,copy=False).set_index(keys=['FspX','FspY'],inplace=True)\n",
    "        # tdf = pd.merge(tdf, fspDof, how='inner', left_index=True,right_index=True)\n",
    "        \n",
    "        # map the FPPs whose FSPs' DOF > the MinDOF\n",
    "        tdf = pd.merge(tdf, fspDof, how='inner', on=['FspId']) #.astype(np.float32,copy=False)\n",
    "        \n",
    "        # calculate DTF\n",
    "        tdf['Dtf_Final'] = tdf['Dof'] - tdf['Dtf']\n",
    "        tdf = tdf[tdf['Dtf_Final'] > 0] # tdf.drop(tdf[tdf['Dtf']<=0].index, inplace=True) # saves memory than tdf = tdf[tdf['Dtf'] > 0]?\n",
    "                \n",
    "        tdf = tdf.groupby(['FppCol', 'FppRow'],as_index=False).agg({'Dtf_Final':'max','FilledDepth':'first'}) #Depth = ('Dtf', max),FilledDepth=('FilledDepth',first))\n",
    "        # print(tdf)\n",
    "        # add the depth of filled drpression\n",
    "        tdf['Dtf_Final'] = tdf['Dtf_Final'] + tdf['FilledDepth']\n",
    "        # drop 'FilledDepth'\n",
    "    else:\n",
    "        print(f'Unsupported fspDof type {fspDof}!')\n",
    "        return None, None, None, None\n",
    "    #\n",
    "    # Turn relations into 2D array\n",
    "    #\n",
    "    if len(tdf)==0:\n",
    "        # no FPP needs to be mapping\n",
    "        return None, None, None, None\n",
    "\n",
    "    # drop off not-used columns in the DF\n",
    "    tdf = tdf[['FppCol','FppRow','Dtf_Final']]\n",
    "    # tdf.drop(columns=['FilledDepth'],axis=1,inplace=True)\n",
    "\n",
    "    # Determine the minimum map extent to speed up the mapping\n",
    "    # original map extent is the FPP's extent\n",
    "    mapMinX,mapMaxX,mapMinY,mapMaxY = fppExtent\n",
    "\n",
    "    # further reduce map extent if FPP extent is reduced\n",
    "    if (not (aoiExtent is None)) or isinstance(fspDof,(int, float)) or isinstance(fspDof, pd.DataFrame):\n",
    "        # further reduce the map extent with the FPPs \n",
    "        mapMinCol,mapMaxCol = tdf['FppCol'].min(),tdf['FppCol'].max()\n",
    "        mapMinRow,mapMaxRow = tdf['FppRow'].min(),tdf['FppRow'].max()\n",
    "        # shift FPP's cols and rows\n",
    "        tdf['FppCol'] = tdf['FppCol']-mapMinCol\n",
    "        tdf['FppRow'] = tdf['FppRow']-mapMinRow\n",
    "        # calculate map's new extent\n",
    "        mapMaxX = mapMinX + (mapMaxCol+1)*cellSize # this line MUST before the next line as the next line changes mapMinX!\n",
    "        mapMinX = mapMinX + mapMinCol*cellSize\n",
    "        mapMinY = mapMaxY - (mapMaxRow+1)*cellSize # this line MUST before the next line as the next line changes mapMaxY!\n",
    "        mapMaxY = mapMaxY - mapMinRow*cellSize\n",
    "    \n",
    "    # print('Map extent (minX, maxX, minY, maxY) :',(mapMinX, mapMaxX, mapMinY, mapMaxY))\n",
    "    # Calculate map rows and columns\n",
    "    tCols = int(round((mapMaxX-mapMinX)/cellSize))\n",
    "    tRows = int(round((mapMaxY-mapMinY)/cellSize))\n",
    "    # print(f'Turn FSP-FPP relations to a 2D array of {tRows, tCols} ...')\n",
    "    \n",
    "    # Initialize the array for saving as a raster\n",
    "    dtfArray =  np.full(shape=(tRows,tCols),fill_value=noData,dtype=np.float32)\n",
    "    \n",
    "    # # update the array with FPP's DTF\n",
    "    for (idx,idy,dtf) in tdf.itertuples(index=False): # itertuples() is the fastest way of iterating a df\n",
    "        # idx,idy,dtf = (getattr(row,'FppCol'),getattr(row,'FppRow'),getattr(row,'Dtf')) \n",
    "        dtfArray[idy,idx] = dtf\n",
    " \n",
    "    return dtfArray, noData, mapMinX, mapMaxY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiled FLDPLN library folder: E:\\CUAHSI_SI\\training\\examples\\wildcat_10m_3dep\\tiled_snz_library\n",
      "Map folder: E:\\CUAHSI_SI\\training\\examples\\wildcat_10m_3dep\\maps\\labor_day_2018_AHPS_reach_outlet\n",
      "Libraries to map: ['lib_py']\n",
      "Map lib_py ...\n",
      "Tiles need to be mapped: [4, 5, 9, 10, 13, 14, 19, 20, 25, 26, 31, 32]\n",
      "10\n",
      "Actual mapped tiles: ['E:\\\\CUAHSI_SI\\\\training\\\\examples\\\\wildcat_10m_3dep\\\\maps\\\\labor_day_2018_AHPS_reach_outlet\\\\lib_py_tile_4.tif', 'E:\\\\CUAHSI_SI\\\\training\\\\examples\\\\wildcat_10m_3dep\\\\maps\\\\labor_day_2018_AHPS_reach_outlet\\\\lib_py_tile_5.tif', 'E:\\\\CUAHSI_SI\\\\training\\\\examples\\\\wildcat_10m_3dep\\\\maps\\\\labor_day_2018_AHPS_reach_outlet\\\\lib_py_tile_9.tif', 'E:\\\\CUAHSI_SI\\\\training\\\\examples\\\\wildcat_10m_3dep\\\\maps\\\\labor_day_2018_AHPS_reach_outlet\\\\lib_py_tile_10.tif', 'E:\\\\CUAHSI_SI\\\\training\\\\examples\\\\wildcat_10m_3dep\\\\maps\\\\labor_day_2018_AHPS_reach_outlet\\\\lib_py_tile_13.tif', 'E:\\\\CUAHSI_SI\\\\training\\\\examples\\\\wildcat_10m_3dep\\\\maps\\\\labor_day_2018_AHPS_reach_outlet\\\\lib_py_tile_14.tif', 'E:\\\\CUAHSI_SI\\\\training\\\\examples\\\\wildcat_10m_3dep\\\\maps\\\\labor_day_2018_AHPS_reach_outlet\\\\lib_py_tile_19.tif', 'E:\\\\CUAHSI_SI\\\\training\\\\examples\\\\wildcat_10m_3dep\\\\maps\\\\labor_day_2018_AHPS_reach_outlet\\\\lib_py_tile_20.tif', 'E:\\\\CUAHSI_SI\\\\training\\\\examples\\\\wildcat_10m_3dep\\\\maps\\\\labor_day_2018_AHPS_reach_outlet\\\\lib_py_tile_25.tif', 'E:\\\\CUAHSI_SI\\\\training\\\\examples\\\\wildcat_10m_3dep\\\\maps\\\\labor_day_2018_AHPS_reach_outlet\\\\lib_py_tile_26.tif', 'E:\\\\CUAHSI_SI\\\\training\\\\examples\\\\wildcat_10m_3dep\\\\maps\\\\labor_day_2018_AHPS_reach_outlet\\\\lib_py_tile_31.tif', 'E:\\\\CUAHSI_SI\\\\training\\\\examples\\\\wildcat_10m_3dep\\\\maps\\\\labor_day_2018_AHPS_reach_outlet\\\\lib_py_tile_32.tif']\n",
      "Mosaic tile maps ...\n",
      "Individual library mapping time: {'lib_py': 0.016}\n",
      "Total processing time (minutes): 0.016\n"
     ]
    }
   ],
   "source": [
    "# show mapping info\n",
    "print(f'Tiled FLDPLN library folder: {libFolder}')\n",
    "print(f'Map folder: {outMapFolder}')\n",
    "# Find libs needs mapping\n",
    "libs2Map = fspDof['LibName'].drop_duplicates().tolist()\n",
    "print(f'Libraries to map: {libs2Map}')\n",
    "\n",
    "# check running time\n",
    "startTimeAllLibs = time.time()\n",
    "\n",
    "# create a local cluster to speed up the mapping. Must be run inside \"if __name__ == '__main__'\"!!!\n",
    "if useLocalCluster:\n",
    "    # cluster = LocalCluster(n_workers=4,processes=False)\n",
    "    try:\n",
    "        print('Start a LocalCluster ...')\n",
    "        # NOTE: set worker space (i.e., local_dir) to a folder that the LocalCluster can access. When run the script through a scheduled task, \n",
    "        # the system uses C:\\Windows\\system32 by default, which a typical user doesn't have the access!\n",
    "        # cluster = LocalCluster(n_workers=numOfWorkers,memory_limit='32GB',local_dir=\"D:/projects_new/fldpln/tools\") # for KARS production server (192G RAM & 8 cores)\n",
    "        # cluster = LocalCluster(n_workers=numOfWorkers,processes=False) # for KARS production server (192G RAM & 8 cores)\n",
    "        cluster = LocalCluster(n_workers=numOfWorkers,memory_limit='8GB',local_dir=\"E:\\temp\") # for office desktop (64G RAM & 8 cores)\n",
    "        # print('Watch workers at: ',cluster.dashboard_link)\n",
    "        print(f'Number of workers: {numOfWorkers}')\n",
    "        client = Client(cluster)\n",
    "        # print scheduler info\n",
    "        # print(client.scheduler_info())\n",
    "    except:\n",
    "        print('Cannot create a LocalCLuster!')\n",
    "        useLocalCluster = False\n",
    "\n",
    "# dict to store lib processing time\n",
    "libTime={}\n",
    "\n",
    "# map each library\n",
    "for libName in libs2Map:\n",
    "    # check running time\n",
    "    startTime = time.time()\n",
    "    \n",
    "    # select the FSPs within the lib\n",
    "    fspIdDof = fspDof[fspDof['LibName']==libName][['FspId','Dof']]\n",
    "    # mapping flood depth\n",
    "    if useLocalCluster:\n",
    "        \n",
    "        print(f'Map [{libName}] using LocalCLuster ...')\n",
    "        # generate a DAG\n",
    "        dag,dagRoot=MapFloodDepthWithTilesAsDag(libFolder,libName,'snappy',outMapFolder,fspIdDof,aoiExtent=None)\n",
    "        if dag is None:\n",
    "            tileTifs = None\n",
    "        else:\n",
    "            # visualize DAG\n",
    "            # visualize(dag)\n",
    "            # Compute DAG\n",
    "            tileTifs = client.get(dag, dagRoot)\n",
    "            if not tileTifs: # list is empty\n",
    "                tileTifs =  None\n",
    "    else:\n",
    "        print(f'Map {libName} ...')\n",
    "        tileTifs = MapFloodDepthWithTiles_v1(libFolder,libName,'snappy',outMapFolder,fspIdDof,aoiExtent=None)\n",
    "    print(f'Actual mapped tiles: {tileTifs}')\n",
    "\n",
    "    # Mosaic all the tiles from a library into one tif file\n",
    "    if mosaicTiles and not(tileTifs is None):\n",
    "        print('Mosaic tile maps ...')\n",
    "        mosaicTifName = libName+'_'+outMapFolderName+'.tif'\n",
    "        # Simplest implementation, may crash with very large raster\n",
    "        MosaicGtifs(outMapFolder,tileTifs,mosaicTifName,keepTifs=False)\n",
    "    \n",
    "    # check time\n",
    "    endTime = time.time()\n",
    "    usedTime = round((endTime-startTime)/60,3)\n",
    "    libTime[libName] = usedTime\n",
    "    # print(f'{libName} processing time (minutes):', usedTime)\n",
    "\n",
    "# Show processing time\n",
    "# Individual lib processing time\n",
    "print('Individual library mapping time:', libTime)\n",
    "# total time\n",
    "endTimeAllLibs = time.time()\n",
    "print('Total processing time (minutes):', round((endTimeAllLibs-startTimeAllLibs)/60,3))\n",
    "\n",
    "#\n",
    "# Shutdown local clusters\n",
    "#\n",
    "if useLocalCluster:\n",
    "    print('Shutdown LocalCluster ...')\n",
    "    cluster.close()\n",
    "    client.shutdown()\n",
    "    client.close()\n",
    "    useLocalCluster = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "acfdeded818a4df3f46e9c2992917120b0a663a2d6c4f04d9d79d65bad4d3fed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
